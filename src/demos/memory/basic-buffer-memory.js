import { BufferMemory } from 'langchain/memory';
import { ConversationChain } from 'langchain/chains';
import { ChatOpenAI } from '@langchain/openai';
import { ChatPromptTemplate, MessagesPlaceholder } from '@langchain/core/prompts';
import dotenv from 'dotenv';

// Load environment variables
dotenv.config();

/**
 * Basic Buffer Memory Demo
 * 
 * This demo shows how to store complete conversation history for context.
 * Buffer memory maintains all previous interactions in the conversation.
 */
async function basicBufferMemoryDemo() {
    console.log('üöÄ Executing Basic Buffer Memory Demo...');
    console.log('=' .repeat(60));

    console.log('üß† Buffer Memory Overview:');
    console.log('   ‚Ä¢ Stores complete conversation history');
    console.log('   ‚Ä¢ Maintains full context for AI responses');
    console.log('   ‚Ä¢ Simple and straightforward implementation');
    console.log('   ‚Ä¢ Best for short to medium conversations');

    // Initialize the model
    const model = new ChatOpenAI({
        apiKey: process.env.OPENAI_API_KEY,
        temperature: 0.7,
        modelName: 'gpt-3.5-turbo'
    });

    console.log('\nü§ñ Model Configuration:');
    console.log('   ‚Ä¢ Model: gpt-3.5-turbo');
    console.log('   ‚Ä¢ Temperature: 0.7');
    console.log('   ‚Ä¢ API Key:', process.env.OPENAI_API_KEY ? '‚úÖ Found' : '‚ùå Missing');

    // Create buffer memory
    const memory = new BufferMemory({
        memoryKey: "chat_history",
        returnMessages: true,
    });

    console.log('\nüíæ Buffer Memory Configuration:');
    console.log('   ‚Ä¢ Memory Key: chat_history');
    console.log('   ‚Ä¢ Return Messages: true');
    console.log('   ‚Ä¢ Storage: In-memory (temporary)');

    // Create conversation chain with memory
    const conversationChain = new ConversationChain({
        llm: model,
        memory: memory,
        verbose: true,
    });

    console.log('\nüîó Conversation Chain Created with Buffer Memory');

    // Simulate a conversation
    const conversationSteps = [
        {
            input: "Hi, my name is Alice and I love programming.",
            description: "Initial introduction with personal information"
        },
        {
            input: "What programming languages do you think I should learn?",
            description: "Follow-up question (AI should remember Alice's interest in programming)"
        },
        {
            input: "I'm particularly interested in web development.",
            description: "Additional context about programming interests"
        },
        {
            input: "What's my name and what do I love?",
            description: "Memory test - AI should recall previous information"
        },
        {
            input: "Can you recommend some web development frameworks?",
            description: "Contextual question based on previous conversation"
        }
    ];

    if (process.env.OPENAI_API_KEY) {
        console.log('\nüó£Ô∏è Starting Conversation Simulation...');
        
        for (let i = 0; i < conversationSteps.length; i++) {
            const step = conversationSteps[i];
            
            console.log(`\n${'='.repeat(50)}`);
            console.log(`üí¨ Conversation Step ${i + 1}`);
            console.log(`${'='.repeat(50)}`);
            
            console.log('üë§ Human:', step.input);
            console.log('üìù Context:', step.description);
            
            try {
                console.log('üîÑ Processing with memory...');
                
                const response = await conversationChain.call({
                    input: step.input
                });
                
                console.log('ü§ñ AI Response:', response.response);
                
                // Show current memory state
                const memoryVariables = await memory.loadMemoryVariables({});
                console.log('üß† Memory State:');
                console.log(`   Messages in memory: ${memoryVariables.chat_history.length}`);
                
                if (i === conversationSteps.length - 1) {
                    console.log('\nüìö Complete Memory History:');
                    memoryVariables.chat_history.forEach((msg, index) => {
                        const role = msg._getType() === 'human' ? 'üë§ Human' : 'ü§ñ AI';
                        console.log(`   ${index + 1}. ${role}: ${msg.content.substring(0, 100)}${msg.content.length > 100 ? '...' : ''}`);
                    });
                }
                
            } catch (error) {
                console.log('‚ùå Error in conversation:', error.message);
            }
            
            // Small delay between steps for readability
            await new Promise(resolve => setTimeout(resolve, 1000));
        }
        
    } else {
        console.log('\n‚ö†Ô∏è  OpenAI API Key not found. Demonstrating memory structure only...');
        
        // Simulate adding messages to memory manually
        for (const step of conversationSteps) {
            console.log(`\nüë§ Human: ${step.input}`);
            console.log(`üìù Context: ${step.description}`);
            
            // Manually save to memory (simulation)
            await memory.saveContext(
                { input: step.input },
                { output: `[Simulated AI response to: ${step.input}]` }
            );
            
            const memoryVars = await memory.loadMemoryVariables({});
            console.log(`üß† Memory now contains ${memoryVars.chat_history.length} messages`);
        }
    }

    // Demonstrate memory operations
    console.log(`\n${'='.repeat(60)}`);
    console.log('üîß Memory Operations Demo');
    console.log(`${'='.repeat(60)}`);

    // Show memory loading
    console.log('\nüìñ Loading Memory Variables:');
    const currentMemory = await memory.loadMemoryVariables({});
    console.log(`   Total messages: ${currentMemory.chat_history.length}`);
    console.log(`   Memory key: ${memory.memoryKey}`);

    // Show memory clearing
    console.log('\nüßπ Memory Management:');
    console.log('   ‚Ä¢ clear(): Removes all conversation history');
    console.log('   ‚Ä¢ saveContext(): Adds new interaction to memory');
    console.log('   ‚Ä¢ loadMemoryVariables(): Retrieves current memory state');

    // Create a second conversation chain to show memory isolation
    console.log('\nüîÑ Memory Isolation Demo:');
    const newMemory = new BufferMemory({
        memoryKey: "chat_history",
        returnMessages: true,
    });

    const newMemoryVars = await newMemory.loadMemoryVariables({});
    console.log(`   New memory instance: ${newMemoryVars.chat_history.length} messages`);
    console.log(`   Original memory: ${currentMemory.chat_history.length} messages`);
    console.log('   ‚úÖ Memory instances are properly isolated');

    // Buffer Memory characteristics
    console.log(`\n${'='.repeat(60)}`);
    console.log('üìä Buffer Memory Characteristics');
    console.log(`${'='.repeat(60)}`);

    console.log('‚úÖ Advantages:');
    console.log('   ‚Ä¢ Complete conversation context preserved');
    console.log('   ‚Ä¢ Simple implementation and usage');
    console.log('   ‚Ä¢ No information loss');
    console.log('   ‚Ä¢ Perfect recall of all interactions');

    console.log('\n‚ö†Ô∏è Considerations:');
    console.log('   ‚Ä¢ Memory usage grows with conversation length');
    console.log('   ‚Ä¢ Token costs increase with longer conversations');
    console.log('   ‚Ä¢ May hit model context limits in very long chats');
    console.log('   ‚Ä¢ No automatic cleanup or summarization');

    console.log('\nüéØ Best Use Cases:');
    console.log('   ‚Ä¢ Short to medium conversations');
    console.log('   ‚Ä¢ When complete context is crucial');
    console.log('   ‚Ä¢ Customer support interactions');
    console.log('   ‚Ä¢ Educational or tutoring applications');

    console.log('\n‚úÖ Basic Buffer Memory Demo completed!');
    console.log('üí° Key takeaways:');
    console.log('   ‚Ä¢ Buffer memory stores complete conversation history');
    console.log('   ‚Ä¢ Provides full context for AI responses');
    console.log('   ‚Ä¢ Simple to implement and understand');
    console.log('   ‚Ä¢ Best for shorter conversations where full context matters');
    console.log('   ‚Ä¢ Memory grows linearly with conversation length');
}

// Execute the demo
basicBufferMemoryDemo().catch(console.error);
